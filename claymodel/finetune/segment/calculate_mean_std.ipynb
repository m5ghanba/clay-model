{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9424b9b-ea9d-433d-a4d4-ab807575549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as trns\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from torch.optim import lr_scheduler\n",
    "import segmentation_models_pytorch as smp\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5562368-ab8a-484e-b926-3c2eaf879b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "11.8\n",
      "cuDNN version: 90100\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)  # Should print the version of CUDA PyTorch is using\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a1e2fb-a697-4245-858a-0729da3c8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for files...\n",
      "Found 515 train images and 515 train masks in 7 folders.\n",
      "Found 62 validation images and 62 validation masks in 1 folders.\n",
      "Found 385 test images and 385 test masks in 2 folders.\n",
      "\n",
      "Train folders:\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20230819T192911_20230819T193100_T09UWT\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20220806T191919_20220806T192707_T09UYQ\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20210727T191911_20210727T192721_T09UXQ\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20230902T190921_20230902T191805_T10UDU\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20230804T192909_20230804T192942_T09UXS\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20230816T191911_20230816T192348_T10UCA\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20230902T195919_20230902T195917_T09UUU\n",
      "\n",
      "Validation folders:\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20220806T191919_20220806T192707_T10UCU\n",
      "\n",
      "Test folders:\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20200908T192939_20200908T193355_T09UWS\n",
      "C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\20200908T192939_20200908T193355_T09UXR\n",
      "Found 962 images and 962 masks.\n",
      "Train samples: 959, Validation samples: 2, Test samples: 1\n",
      "Train samples: 712\n",
      "Validation samples: 179\n",
      "Test samples: 71\n",
      "\n",
      "Test folder(s):\n",
      "['C:\\\\Annotated Dataset\\\\L2A Data\\\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\\\20230816T191911_20230816T192348_T10UCA']\n"
     ]
    }
   ],
   "source": [
    "# The spawn multiprocessing method used on Windows struggles to transfer code defined dynamically within a notebook's __main__ scope to new worker \n",
    "# processes. Moving the Dataset definition to an importable .py file provides a reliable way for the worker processes to access the necessary code \n",
    "# definition via standard Python imports.\n",
    "from utils import *   \n",
    "\n",
    "\n",
    "# Data Loading\n",
    "print(\"Scanning for files...\")\n",
    "image_files = []\n",
    "mask_files = []\n",
    "# path to the directory containing labeled data\n",
    "# ├── Folder1\\\n",
    "# │   ├── images\\\n",
    "# │   │   ├── tile_0_image.tiff\n",
    "# │   │   ├── ...\n",
    "# │   ├── masks\\\n",
    "# │   │   ├── tile_0_mask.tiff\n",
    "# │   │   ├── ...\n",
    "# ├── Folder2\\\n",
    "# │   ├── images\\\n",
    "# │   │   ├── tile_0_image.tiff\n",
    "# │   │   ├── ...\n",
    "# │   ├── masks\\\n",
    "# │   │   ├── tile_0_mask.tiff\n",
    "# │   │   ├── ...\n",
    "# └── ... (other main folders)\n",
    "data_root = r\"C:\\Annotated Dataset\\L2A Data\\Tiles10and20mbandsSubsBathy_G0Percent_stride256\\*\"  #C:\\Dataset\\Ultimate10and20mbandsSubsBathy\\*    C:\\Dataset\\Ultimate10and20mbandsSubsBathyReRevised\\*\n",
    "folders = glob.glob(data_root)\n",
    "folders = sorted(folders)\n",
    "if not folders:\n",
    "    print(f\"Warning: No folders found at {data_root}\")\n",
    "\n",
    "\n",
    "\n",
    "# Selecting 70% of the folders for training, 15% for validation, and 15% for test (did this to use geographically independent data for tr, val, and test.\n",
    "# Create a list of all folder paths\n",
    "all_folders = [f for f in folders if os.path.isdir(f)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_folders)\n",
    "\n",
    "num_folders = len(all_folders)\n",
    "train_split = int(0.70 * num_folders)\n",
    "val_split = int(0.15 * num_folders)\n",
    "\n",
    "\n",
    "# ############ FIX THIS ###############\n",
    "# train_split = 4\n",
    "# val_split = 1\n",
    "\n",
    "\n",
    "\n",
    "train_folders = all_folders[:train_split]\n",
    "val_folders = all_folders[train_split:train_split + val_split]\n",
    "test_folders = all_folders[train_split + val_split:]\n",
    "\n",
    "def get_files_from_folders(folder_list):\n",
    "    image_paths = []\n",
    "    mask_paths = []\n",
    "    for f in folder_list:\n",
    "        image_subfolder = os.path.join(f, \"images\")\n",
    "        mask_subfolder = os.path.join(f, \"masks\")\n",
    "        if os.path.isdir(image_subfolder) and os.path.isdir(mask_subfolder):\n",
    "            image_paths.extend(glob.glob(os.path.join(image_subfolder, \"*\")))\n",
    "            mask_paths.extend(glob.glob(os.path.join(mask_subfolder, \"*\")))\n",
    "        else:\n",
    "            print(f\"Warning: Folder {f} did not contain 'images' and 'masks' subfolders.\")\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "X_train_paths, y_train_paths = get_files_from_folders(train_folders)\n",
    "X_val_paths, y_val_paths = get_files_from_folders(val_folders)\n",
    "X_test_paths, y_test_paths = get_files_from_folders(test_folders)\n",
    "\n",
    "print(f\"Found {len(X_train_paths)} train images and {len(y_train_paths)} train masks in {len(train_folders)} folders.\")\n",
    "print(f\"Found {len(X_val_paths)} validation images and {len(y_val_paths)} validation masks in {len(val_folders)} folders.\")\n",
    "print(f\"Found {len(X_test_paths)} test images and {len(y_test_paths)} test masks in {len(test_folders)} folders.\")\n",
    "\n",
    "# Basic check if counts are reasonable\n",
    "if len(X_train_paths) != len(y_train_paths) or \\\n",
    "   len(X_val_paths) != len(y_val_paths) or \\\n",
    "   len(X_test_paths) != len(y_test_paths):\n",
    "    raise ValueError(\"Mismatch in the number of image and mask files in one or more splits.\")\n",
    "\n",
    "\n",
    "print(\"\\nTrain folders:\")\n",
    "for folder in train_folders:\n",
    "    print(folder)\n",
    "\n",
    "print(\"\\nValidation folders:\")\n",
    "for folder in val_folders:\n",
    "    print(folder)\n",
    "\n",
    "print(\"\\nTest folders:\")\n",
    "for folder in test_folders:\n",
    "    print(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # For random splitting, uncomment the following\n",
    "for f in folders:\n",
    "    files = glob.glob(f\"{f}/*\")\n",
    "    # Basic check if expected subfolders/files exist\n",
    "    if len(files) >= 2:\n",
    "        image_files.extend(glob.glob(f\"{files[0]}/*\"))\n",
    "        mask_files.extend(glob.glob(f\"{files[1]}/*\"))\n",
    "    else:\n",
    "        print(f\"Warning: Folder {f} did not contain expected structure.\")\n",
    "\n",
    "print(f\"Found {len(image_files)} images and {len(mask_files)} masks.\")\n",
    "\n",
    "# Ensure we have data before splitting\n",
    "if not image_files or not mask_files or len(image_files) != len(mask_files):\n",
    "    raise ValueError(\"Mismatch in image/mask files or no files found. Check paths.\")\n",
    "\n",
    "# Proceed with splitting only if files were found\n",
    "X_train_paths, X_temp_paths, y_train_paths, y_temp_paths = train_test_split(\n",
    "    image_files, mask_files, test_size=0.003, random_state=42 # Use random_state!             0.3\n",
    ")\n",
    "X_val_paths, X_test_paths, y_val_paths, y_test_paths = train_test_split(\n",
    "    X_temp_paths, y_temp_paths, test_size=0.005, random_state=42 # Use same random_state               0.5\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train_paths)}, Validation samples: {len(X_val_paths)}, Test samples: {len(X_test_paths)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use data from a few folders for testing and shuffle the rest for tr and val (80-20)\n",
    "# --- Step 1: Assign second folder as test ---\n",
    "if len(folders) < 2:\n",
    "    raise ValueError(\"At least 2 folders are required to assign one for testing.\")\n",
    "\n",
    "test_indices = [6]  # Use whatever indices you want here eg [9,1,3]\n",
    "test_folders = [folders[i] for i in test_indices]\n",
    "\n",
    "# Get image/mask paths for test folder\n",
    "X_test_paths, y_test_paths = get_files_from_folders(test_folders)\n",
    "\n",
    "# Exclude the actual test folder from train/val\n",
    "# train_val_folders = [f for i, f in enumerate(folders) if i != test_index]\n",
    "train_val_folders = [f for i, f in enumerate(folders) if i not in test_indices]\n",
    "\n",
    "# Gather all image/mask file paths\n",
    "X_all_paths, y_all_paths = get_files_from_folders(train_val_folders)\n",
    "\n",
    "# --- Step 3: Shuffle the image/mask files together (zip to keep them aligned) ---\n",
    "combined = list(zip(X_all_paths, y_all_paths))\n",
    "random.seed(42)\n",
    "random.shuffle(combined)\n",
    "X_all_paths[:], y_all_paths[:] = zip(*combined)\n",
    "\n",
    "# --- Step 4: Split 80% for training, 20% for validation ---\n",
    "split_idx = int(0.8 * len(X_all_paths))\n",
    "X_train_paths = X_all_paths[:split_idx]\n",
    "y_train_paths = y_all_paths[:split_idx]\n",
    "X_val_paths = X_all_paths[split_idx:]\n",
    "y_val_paths = y_all_paths[split_idx:]\n",
    "\n",
    "# --- Reporting ---\n",
    "print(f\"Train samples: {len(X_train_paths)}\")\n",
    "print(f\"Validation samples: {len(X_val_paths)}\")\n",
    "print(f\"Test samples: {len(X_test_paths)}\")\n",
    "\n",
    "# --- Sanity check ---\n",
    "if len(X_train_paths) != len(y_train_paths) or \\\n",
    "   len(X_val_paths) != len(y_val_paths) or \\\n",
    "   len(X_test_paths) != len(y_test_paths):\n",
    "    raise ValueError(\"Mismatch in image and mask counts in one or more splits.\")\n",
    "\n",
    "print(\"\\nTest folder(s):\")\n",
    "print(test_folders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071651ed-288e-47a1-b97a-d874411daa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation:  The function returns an instance of the A.Compose class. This instance is an object that, when called with an image and mask \n",
    "# (as keyword arguments image= and mask=), will apply the defined sequence of augmentations to them and return a dictionary containing the \n",
    "# augmented image and mask.\n",
    "# The get_training_augmentation() function is designed to create the augmentation pipeline. It's not meant to directly perform the augmentation on a \n",
    "# specific image and mask. The A.Compose object that it returns is the callable that takes the image and mask as input later, when it's called within \n",
    "# the __getitem__ method inside the SatelliteDataset class\n",
    "def get_training_augmentation():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            # A.RandomRotate90(p=0.5)\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119ccc83-279c-4a8f-b05e-4b088133a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"kelp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d02e568-c2f8-40ee-a3f6-9c034dec5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std for normalization using training data\n",
    "# Create a DataLoader for the training data (without augmentation)\n",
    "temp_train_dataset = SatelliteDataset(\n",
    "    image_paths=X_train_paths,\n",
    "    mask_paths=y_train_paths,\n",
    "    classes=CLASSES,\n",
    "    augmentation=None,\n",
    "    mean=None,\n",
    "    std=None\n",
    ")\n",
    "# We use DataLoader to load images in batches, which is much more efficient for I/O and can leverage multiple CPU cores (num_workers).\n",
    "temp_train_loader = DataLoader(temp_train_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=True) # Adjust batch_size and num_workers as needed\n",
    "\n",
    "# Initialize accumulators for mean and std\n",
    "sum_per_channel = None\n",
    "sum_sq_per_channel = None\n",
    "total_pixels = 0\n",
    "num_channels = None\n",
    "\n",
    "# Iterate through the DataLoader to calculate mean and std\n",
    "for batch_idx, (images, _) in enumerate(temp_train_loader):\n",
    "    # images shape: (batch_size, C, H, W)\n",
    "    batch_size, C, H, W = images.shape\n",
    "    images = images.numpy() # Move to NumPy for easier calculations\n",
    "\n",
    "    if num_channels is None:\n",
    "        num_channels = C\n",
    "\n",
    "    # Sum across batch, height, and width for each channel\n",
    "    current_sum = np.sum(images, axis=(0, 2, 3)) # Shape: (C,)\n",
    "    current_sum_sq = np.sum(images ** 2, axis=(0, 2, 3)) # Shape: (C,)\n",
    "    current_pixels = batch_size * H * W\n",
    "\n",
    "    if sum_per_channel is None:\n",
    "        sum_per_channel = current_sum\n",
    "        sum_sq_per_channel = current_sum_sq\n",
    "    else:\n",
    "        sum_per_channel += current_sum\n",
    "        sum_sq_per_channel += current_sum_sq\n",
    "    total_pixels += current_pixels\n",
    "\n",
    "# Calculate the mean and std\n",
    "mean_per_channel = sum_per_channel / total_pixels\n",
    "std_per_channel = np.sqrt((sum_sq_per_channel / total_pixels) - (mean_per_channel ** 2))\n",
    "\n",
    "# print(\"Calculated Mean per channel:\", mean_per_channel)\n",
    "# print(\"Calculated Std per channel:\", std_per_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e976bbc6-41f2-41c7-b527-0657c23f30cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Mean per channel: [ 1.9271057e+02  2.4526277e+02  1.3288297e+02  9.1582831e+02\n",
      "  2.9818857e+02  7.2954968e+02  8.6662543e+02  9.5027246e+02\n",
      "  4.1283145e+02  2.0912796e+02  1.3694173e+00 -4.0696268e+00\n",
      "  1.7028417e-02  2.0986709e-01 -2.0986709e-01  1.4291023e+07\n",
      "  8.4679022e-02]\n",
      "Calculated Std per channel: [1.5137001e+02 2.0824329e+02 1.9422487e+02 1.2421727e+03 3.6834180e+02\n",
      " 9.6155676e+02 1.1546597e+03 1.2775868e+03 5.8319891e+02 3.3291693e+02\n",
      " 1.3369064e+00 2.1212910e+02 6.7632693e-01 7.2675657e-01 7.2675657e-01\n",
      " 1.8433802e+10 4.1082326e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculated Mean per channel:\", mean_per_channel)\n",
    "print(\"Calculated Std per channel:\", std_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd41e64-cfd2-4636-98f4-d304a35a2cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (claymodel-env)",
   "language": "python",
   "name": "claymodel-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
